{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor-Critic - QMIX \n",
    "\n",
    "Skorzystamy z petting zoo i gotowego [SAC z Stable Baselines3](https://stable-baselines3.readthedocs.io/en/master/modules/sac.html)\n",
    "\n",
    "Actor-critic \n",
    "\n",
    " * 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (2.4.1)\n",
      "Requirement already satisfied: numpy in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: torch in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: supersuit in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (3.9.3)\n",
      "Requirement already satisfied: pettingzoo in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (1.24.3)\n",
      "Requirement already satisfied: pymunk in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (6.10.0)\n",
      "Requirement already satisfied: scipy in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (1.15.0)\n",
      "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from stable-baselines3) (0.29.1)\n",
      "Requirement already satisfied: cloudpickle in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from stable-baselines3) (3.0.0)\n",
      "Requirement already satisfied: pandas in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from stable-baselines3) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from stable-baselines3) (3.9.2)\n",
      "Requirement already satisfied: filelock in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: tinyscaler>=1.2.6 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from supersuit) (1.2.8)\n",
      "Requirement already satisfied: cffi>=1.17.1 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from pymunk) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from cffi>=1.17.1->pymunk) (2.22)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from pandas->stable-baselines3) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from pandas->stable-baselines3) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/michal/miniconda/envs/drlzh/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install stable-baselines3 numpy torch supersuit pettingzoo pymunk scipy\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "import supersuit as ss\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "\n",
    "from stable_baselines3.ppo import CnnPolicy, MlpPolicy\n",
    "\n",
    "from pettingzoo.butterfly import knights_archers_zombies_v10\n",
    "from pettingzoo.sisl import waterworld_v4\n",
    "from pettingzoo.butterfly import pistonball_v6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env_fn, steps: int = 10_000, seed: int | None = 0, **env_kwargs):\n",
    "    # Train a single model to play as each agent in an AEC environment\n",
    "    env = env_fn.parallel_env(**env_kwargs)\n",
    "\n",
    "    # Add black death wrapper so the number of agents stays constant\n",
    "    # MarkovVectorEnv does not support environments with varying numbers of active agents unless black_death is set to True\n",
    "    env = ss.black_death_v3(env)\n",
    "\n",
    "    # Pre-process using SuperSuit\n",
    "    visual_observation = not env.unwrapped.vector_state\n",
    "    if visual_observation:\n",
    "        # If the observation space is visual, reduce the color channels, resize from 512px to 84px, and apply frame stacking\n",
    "        env = ss.color_reduction_v0(env, mode=\"B\")\n",
    "        env = ss.resize_v1(env, x_size=84, y_size=84)\n",
    "        env = ss.frame_stack_v1(env, 3)\n",
    "\n",
    "    env.reset(seed=seed)\n",
    "\n",
    "    print(f\"Starting training on {str(env.metadata['name'])}.\")\n",
    "\n",
    "    env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
    "    env = ss.concat_vec_envs_v1(env, 8, num_cpus=1, base_class=\"stable_baselines3\")\n",
    "\n",
    "    # Use a CNN policy if the observation space is visual\n",
    "    model = PPO(\n",
    "        CnnPolicy if visual_observation else MlpPolicy,\n",
    "        env,\n",
    "        verbose=3,\n",
    "        batch_size=256,\n",
    "    )\n",
    "\n",
    "    model.learn(total_timesteps=steps)\n",
    "\n",
    "    model.save(f\"{env.unwrapped.metadata.get('name')}_{time.strftime('%Y%m%d-%H%M%S')}\")\n",
    "\n",
    "    print(\"Model has been saved.\")\n",
    "\n",
    "    print(f\"Finished training on {str(env.unwrapped.metadata['name'])}.\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "def eval(env_fn, num_games: int = 100, render_mode: str | None = None, **env_kwargs):\n",
    "    # Evaluate a trained agent vs a random agent\n",
    "    env = env_fn.env(render_mode=render_mode, **env_kwargs)\n",
    "\n",
    "    # Pre-process using SuperSuit\n",
    "    visual_observation = not env.unwrapped.vector_state\n",
    "    if visual_observation:\n",
    "        # If the observation space is visual, reduce the color channels, resize from 512px to 84px, and apply frame stacking\n",
    "        env = ss.color_reduction_v0(env, mode=\"B\")\n",
    "        env = ss.resize_v1(env, x_size=84, y_size=84)\n",
    "        env = ss.frame_stack_v1(env, 3)\n",
    "\n",
    "    print(\n",
    "        f\"\\nStarting evaluation on {str(env.metadata['name'])} (num_games={num_games}, render_mode={render_mode})\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        latest_policy = max(\n",
    "            glob.glob(f\"{env.metadata['name']}*.zip\"), key=os.path.getctime\n",
    "        )\n",
    "    except ValueError:\n",
    "        print(\"Policy not found.\")\n",
    "        exit(0)\n",
    "\n",
    "    model = PPO.load(latest_policy)\n",
    "\n",
    "    rewards = {agent: 0 for agent in env.possible_agents}\n",
    "\n",
    "    # Note: we evaluate here using an AEC environments, to allow for easy A/B testing against random policies\n",
    "    # For example, we can see here that using a random agent for archer_0 results in less points than the trained agent\n",
    "    for i in range(num_games):\n",
    "        env.reset(seed=i)\n",
    "        env.action_space(env.possible_agents[0]).seed(i)\n",
    "\n",
    "        for agent in env.agent_iter():\n",
    "            obs, reward, termination, truncation, info = env.last()\n",
    "\n",
    "            for a in env.agents:\n",
    "                rewards[a] += env.rewards[a]\n",
    "\n",
    "            if termination or truncation:\n",
    "                break\n",
    "            else:\n",
    "                if agent == env.possible_agents[0]:\n",
    "                    act = env.action_space(agent).sample()\n",
    "                else:\n",
    "                    act = model.predict(obs, deterministic=True)[0]\n",
    "            env.step(act)\n",
    "    env.close()\n",
    "\n",
    "    avg_reward = sum(rewards.values()) / len(rewards.values())\n",
    "    avg_reward_per_agent = {\n",
    "        agent: rewards[agent] / num_games for agent in env.possible_agents\n",
    "    }\n",
    "    print(f\"Avg reward: {avg_reward}\")\n",
    "    print(\"Avg reward per agent, per game: \", avg_reward_per_agent)\n",
    "    print(\"Full rewards: \", rewards)\n",
    "    return avg_reward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on pistonball_v6.\n",
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "env_fn = knights_archers_zombies_v10\n",
    "\n",
    "# Set vector_state to false in order to use visual observations (significantly longer training time)\n",
    "env_kwargs = dict(max_cycles=100, max_zombies=4, vector_state=True)\n",
    "\n",
    "# Train a model (takes ~5 minutes on a laptop CPU)\n",
    "train(env_fn, steps=81_920, seed=0, **env_kwargs)\n",
    "\n",
    "# Evaluate 10 games (takes ~10 seconds on a laptop CPU)\n",
    "eval(env_fn, num_games=10, render_mode=None, **env_kwargs)\n",
    "\n",
    "# Watch 2 games (takes ~10 seconds on a laptop CPU)\n",
    "eval(env_fn, num_games=2, render_mode=\"human\", **env_kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlzh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
